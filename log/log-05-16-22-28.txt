2024-05-16 22-28-14: batch_size: 1024 device: cuda embedSize: 64 gcn_layers: 2 lr: 0.001 n_epochs: 50 pretrained: False ratio: 0.8
2024-05-16 22-28-40: Epoch0:trainLoss7.1204,testLoss9.4686
2024-05-16 22-29-03: Epoch1:trainLoss3.5929,testLoss6.2993
2024-05-16 22-29-24: Epoch2:trainLoss3.7759,testLoss4.3659
2024-05-16 22-29-43: Epoch3:trainLoss3.5432,testLoss3.4297
2024-05-16 22-30-06: Epoch4:trainLoss9.8955,testLoss3.0815
2024-05-16 22-30-32: Epoch5:trainLoss3.4054,testLoss5.0419
2024-05-16 22-30-51: Epoch6:trainLoss3.2581,testLoss2.9825
2024-05-16 22-31-11: Epoch7:trainLoss2.3887,testLoss5.3589
2024-05-16 22-31-30: Epoch8:trainLoss2.7264,testLoss2.7958
2024-05-16 22-31-47: Epoch9:trainLoss2.5455,testLoss2.8670
2024-05-16 22-32-11: Epoch10:trainLoss2.8767,testLoss2.5091
2024-05-16 22-32-46: Epoch11:trainLoss2.6945,testLoss2.7035
2024-05-16 22-33-20: Epoch12:trainLoss1.7505,testLoss2.0876
2024-05-16 22-33-54: Epoch13:trainLoss2.0945,testLoss2.2307
2024-05-16 22-34-28: Epoch14:trainLoss2.2605,testLoss2.0041
2024-05-16 22-35-02: Epoch15:trainLoss1.7250,testLoss2.8312
2024-05-16 22-35-36: Epoch16:trainLoss2.3691,testLoss2.1653
2024-05-16 22-36-09: Epoch17:trainLoss2.0761,testLoss1.9730
2024-05-16 22-36-36: Epoch18:trainLoss2.6713,testLoss2.3640
2024-05-16 22-37-10: Epoch19:trainLoss1.9630,testLoss2.3335
2024-05-16 22-37-44: Epoch20:trainLoss1.7056,testLoss1.9676
2024-05-16 22-38-18: Epoch21:trainLoss2.2325,testLoss1.6937
2024-05-16 22-38-54: Epoch22:trainLoss2.0892,testLoss1.7488
2024-05-16 22-39-26: Epoch23:trainLoss2.0206,testLoss1.8418
2024-05-16 22-39-51: Epoch24:trainLoss1.6781,testLoss1.7884
2024-05-16 22-40-29: Epoch25:trainLoss1.6743,testLoss1.9967
2024-05-16 22-40-57: Epoch26:trainLoss1.5143,testLoss1.9971
2024-05-16 22-41-32: Epoch27:trainLoss1.7851,testLoss1.7149
2024-05-16 22-42-07: Epoch28:trainLoss1.9479,testLoss1.7693
2024-05-16 22-42-39: Epoch29:trainLoss2.6749,testLoss1.6093
2024-05-16 22-43-00: Epoch30:trainLoss1.5088,testLoss1.8971
2024-05-16 22-43-34: Epoch31:trainLoss1.4258,testLoss1.5663
2024-05-16 22-44-08: Epoch32:trainLoss2.0435,testLoss1.6257
2024-05-16 22-44-43: Epoch33:trainLoss1.6700,testLoss1.6444
2024-05-16 22-45-17: Epoch34:trainLoss1.5106,testLoss1.7075
2024-05-16 22-45-51: Epoch35:trainLoss1.6430,testLoss1.7491
2024-05-16 22-46-20: Epoch36:trainLoss2.7642,testLoss1.4667
2024-05-16 22-46-39: Epoch37:trainLoss1.5477,testLoss2.2944
2024-05-16 22-46-58: Epoch38:trainLoss1.4860,testLoss1.4680
2024-05-16 22-47-17: Epoch39:trainLoss1.2521,testLoss1.6576
2024-05-16 22-47-34: Epoch40:trainLoss1.4105,testLoss1.5431
2024-05-16 22-47-52: Epoch41:trainLoss1.4714,testLoss1.4697
2024-05-16 22-48-11: Epoch42:trainLoss1.5304,testLoss1.4163
2024-05-16 22-48-30: Epoch43:trainLoss1.2044,testLoss1.6551
2024-05-16 22-48-53: Epoch44:trainLoss1.2850,testLoss1.5678
2024-05-16 22-49-15: Epoch45:trainLoss1.4156,testLoss1.5603
2024-05-16 22-49-33: Epoch46:trainLoss1.7334,testLoss1.4425
2024-05-16 22-49-52: Epoch47:trainLoss1.2129,testLoss1.4394
2024-05-16 22-50-10: Epoch48:trainLoss2.0803,testLoss1.6098
2024-05-16 22-50-29: Epoch49:trainLoss1.6113,testLoss1.4401
